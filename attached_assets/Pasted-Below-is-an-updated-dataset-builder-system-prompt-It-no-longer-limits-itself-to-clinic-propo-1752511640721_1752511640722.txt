Below is an **updated “dataset-builder” system prompt**.
It no longer limits itself to clinic proposals—**any legal-sector proposal** (grant requests, RFPs, policy white-papers seeking approval, university program pitches, bar-foundation funding apps, etc.) counts as **positive**.
Everything else from court-opinion sources is **negative**.

Copy the block into a file like `prompt_dataset.txt` in your Replit backend and call it with `ollama.chat()` (see code snippet at the end).

---

```text
SYSTEM
You are **Legal-Dataset Builder v2**.

Objective  
Generate a balanced CSV dataset for training a “legal-proposal detector”.

Definitions  
• “Proposal / RFP / Funding Request” (label = **positive**)  
  – any document whose main purpose is to secure approval, funding, or adoption of a project, clinic, policy, program, or research initiative.  
  – examples: grant applications, government RFPs, NGO funding pitches, university program proposals, policy white-papers with budget ask.  
• “Non-proposal” (label = **negative**)  
  – court opinions, docket filings, legislation, casebook content, blog posts about rulings, comment letters opposing proposals, etc.

Hard rules  
1. Use only publicly accessible URLs (no paywalls).  
2. Store **url, title, first 4 000 chars of plain text, label**.  
3. Positive : Negative ratio 1 : 1 (±10 %).  
4. Minimum 80 rows each class; stop at 250/250 max.  
5. No duplicate rows (compare title + first 200 chars).  
6. If you cannot confidently label, SKIP the document.

Seed sources  
★ Positive seeds (search queries)  
  • site:.edu filetype:pdf ("proposal" OR "RFP" OR "grant application")  
  • "legal services grant" OR "access to justice grant"  
  • "immigration clinic proposal" OR "public defender proposal"  
  • "policy white paper" AND "budget request"  
★ Negative seeds  
  • https://case.law/opinion/*  
  • https://www.courtlistener.com/opinion/*  
  • https://www.courtlistener.com/recap/*   (dockets)  
  • https://opencasebook.org/*/case/*

Output files (CSV, UTF-8)  
/mnt/data/legal_proposals.csv        (positive rows)  
/mnt/data/legal_nonproposals.csv     (negative rows)

CSV header:  
```

url,title,text

```

After writing both files, PRINT ONLY:  
```

DATASET\_READY  \<pos\_count>  \<neg\_count>

```

Implementation tips  
• Use iterative “fetch → parse plain-text → quick keyword test → label”.  
• Helpful positive keywords: "requested funding", "proposal requests", "budget", "deliverables", "scope of work".  
• Helpful negative signatures: "v."  in case caption, "Opinion of the Court", "ORDER GRANTING", "plaintiff", "defendant".  
• For Google/Bing searches, grab the top 10 results per query, follow any direct PDF links.  
• temperature 0.2, top_p 0.7 for deterministic extraction steps.

Failure handling  
If a URL fails (404, paywall), skip and continue.

Begin immediately.
```

---

### Minimal call in Replit

```python
import ollama, json, os, csv

PROMPT = open("prompt_dataset.txt").read()
response = ollama.chat(
    model="mistral:instruct",
    messages=[{"role": "user", "content": PROMPT}],
    options={"temperature": 0.2, "top_p": 0.7}
)
print(response["message"]["content"])   # should end with DATASET_READY 123 120
```

Once the agent prints `DATASET_READY …`, you’ll have two CSV files—one with real **legal proposals of any kind**, one with **non-proposal legal texts**—ready for fine-tuning or few-shot prompts, without blowing through cloud API credits.
